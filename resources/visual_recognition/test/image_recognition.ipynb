{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hDulQU02gkpl"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os \n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from keras import Model\n","from keras.applications.densenet import DenseNet121\n","from keras.applications import vgg16\n","from keras.preprocessing import image\n","from keras.applications.densenet import preprocess_input, decode_predictions\n","from keras.layers import GlobalMaxPooling2D\n","from keras.utils.vis_utils import plot_model\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import pathlib\n","from sklearn.metrics.pairwise import linear_kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvWAub1fgkpv","outputId":"88032ce8-ee24-4350-b4ca-4cdcf7a3e0fa"},"outputs":[{"data":{"text/plain":["['images', 'myntradataset', 'styles.csv']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["path = 'archive/'\n","dataset_path = pathlib.Path(path)\n","dirs_names = os.listdir(dataset_path) # list content of dataset\n","dirs_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7RMewEtgkpw","outputId":"c20accef-1b89-42a6-b4d0-48ad8544755b"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\349633451.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  styles_df = pd.read_csv(path + \"styles.csv\", nrows=40000, error_bad_lines=False) # Read n product and drop bad lines\n","Skipping line 6044: expected 10 fields, saw 11\n","Skipping line 6569: expected 10 fields, saw 11\n","Skipping line 7399: expected 10 fields, saw 11\n","Skipping line 7939: expected 10 fields, saw 11\n","Skipping line 9026: expected 10 fields, saw 11\n","Skipping line 10264: expected 10 fields, saw 11\n","Skipping line 10427: expected 10 fields, saw 11\n","Skipping line 10905: expected 10 fields, saw 11\n","Skipping line 11373: expected 10 fields, saw 11\n","Skipping line 11945: expected 10 fields, saw 11\n","Skipping line 14112: expected 10 fields, saw 11\n","Skipping line 14532: expected 10 fields, saw 11\n","Skipping line 15076: expected 10 fields, saw 12\n","Skipping line 29906: expected 10 fields, saw 11\n","Skipping line 31625: expected 10 fields, saw 11\n","Skipping line 33020: expected 10 fields, saw 11\n","Skipping line 35748: expected 10 fields, saw 11\n","Skipping line 35962: expected 10 fields, saw 11\n","Skipping line 37770: expected 10 fields, saw 11\n","Skipping line 38105: expected 10 fields, saw 11\n","Skipping line 38275: expected 10 fields, saw 11\n","Skipping line 38404: expected 10 fields, saw 12\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>gender</th>\n","      <th>masterCategory</th>\n","      <th>subCategory</th>\n","      <th>articleType</th>\n","      <th>baseColour</th>\n","      <th>season</th>\n","      <th>year</th>\n","      <th>usage</th>\n","      <th>productDisplayName</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15970</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Topwear</td>\n","      <td>Shirts</td>\n","      <td>Navy Blue</td>\n","      <td>Fall</td>\n","      <td>2011.0</td>\n","      <td>Casual</td>\n","      <td>Turtle Check Men Navy Blue Shirt</td>\n","      <td>15970.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39386</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Bottomwear</td>\n","      <td>Jeans</td>\n","      <td>Blue</td>\n","      <td>Summer</td>\n","      <td>2012.0</td>\n","      <td>Casual</td>\n","      <td>Peter England Men Party Blue Jeans</td>\n","      <td>39386.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>59263</td>\n","      <td>Women</td>\n","      <td>Accessories</td>\n","      <td>Watches</td>\n","      <td>Watches</td>\n","      <td>Silver</td>\n","      <td>Winter</td>\n","      <td>2016.0</td>\n","      <td>Casual</td>\n","      <td>Titan Women Silver Watch</td>\n","      <td>59263.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21379</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Bottomwear</td>\n","      <td>Track Pants</td>\n","      <td>Black</td>\n","      <td>Fall</td>\n","      <td>2011.0</td>\n","      <td>Casual</td>\n","      <td>Manchester United Men Solid Black Track Pants</td>\n","      <td>21379.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>53759</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Topwear</td>\n","      <td>Tshirts</td>\n","      <td>Grey</td>\n","      <td>Summer</td>\n","      <td>2012.0</td>\n","      <td>Casual</td>\n","      <td>Puma Men Grey T-shirt</td>\n","      <td>53759.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id gender masterCategory subCategory  articleType baseColour  season  \\\n","0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n","1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n","2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n","3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n","4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n","\n","     year   usage                             productDisplayName      image  \n","0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  15970.jpg  \n","1  2012.0  Casual             Peter England Men Party Blue Jeans  39386.jpg  \n","2  2016.0  Casual                       Titan Women Silver Watch  59263.jpg  \n","3  2011.0  Casual  Manchester United Men Solid Black Track Pants  21379.jpg  \n","4  2012.0  Casual                          Puma Men Grey T-shirt  53759.jpg  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["styles_df = pd.read_csv(path + \"styles.csv\", nrows=40000, error_bad_lines=False) # Read n product and drop bad lines \n","styles_df['image'] = styles_df.apply(lambda x: str(x['id']) + \".jpg\", axis=1) # Make image column contains (id.jpg)\n","styles_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZT-nng_Egkpx"},"outputs":[],"source":["#plt.figure(figsize=(7,20))\n","#styles_df.articleType.value_counts().sort_values().plot(kind='barh')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3qVeLhcgkpy","outputId":"743b2315-3675-48f4-bfb8-526f6f72fa8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Tshirts', 'Shirts', 'Casual Shoes', 'Watches', 'Sports Shoes',\n","       'Kurtas', 'Tops', 'Handbags', 'Heels', 'Sunglasses', 'Wallets',\n","       'Flip Flops', 'Sandals', 'Briefs', 'Belts', 'Backpacks', 'Socks',\n","       'Formal Shoes', 'Perfume and Body Mist', 'Jeans', 'Shorts', 'Trousers',\n","       'Flats', 'Dresses', 'Bra'],\n","      dtype='object')\n","[53759, 1855, 7990, 4729, 3954, 5891, 38630, 10866, 15528, 2288, 18237, 13419, 5865, 29584, 9694, 8322, 7964, 17240, 3365, 10065, 15970, 30805, 26960, 12369, 37812, 56825, 9452, 4943, 9660, 15984, 59297, 7158, 16392, 6617, 22395, 12500, 16530, 7167, 12190, 14055, 9204, 39988, 22198, 29570, 26538, 49495, 19311, 49461, 23849, 24250, 15517, 4140, 6425, 42270, 32751, 39943, 22705, 50741, 20856, 19772, 59263, 30039, 29928, 17429, 51658, 23278, 44984, 11188, 45258, 44970, 22950, 13841, 8110, 43190, 32335, 56670, 36795, 40527, 45869, 4716, 3168, 6628, 33822, 42089, 23882, 34835, 12993, 42042, 17416, 12958, 46086, 54543, 4524, 36137, 8913, 5402, 43356, 12994, 34832, 23885, 20099, 28690, 45856, 54588, 24406, 27283, 42426, 50325, 27277, 31312, 33021, 33019, 28697, 27089, 33026, 58719, 28836, 39178, 50322, 27270, 42419, 49653, 58513, 34009, 31782, 40143, 21174, 23623, 10401, 37223, 25520, 32597, 57100, 19578, 27879, 13270, 31120, 40385, 33213, 39729, 47957, 47359, 21977, 58183, 29742, 42841, 35913, 31923, 58177, 21510, 21948, 47366, 9009, 47392, 3391, 20604, 25144, 31924, 42846, 53934, 54118, 2872, 11518, 54127, 55657, 14431, 14409, 34455, 20267, 55650, 22539, 54129, 57303, 11516, 35783, 46615, 10292, 50784, 2888, 15526, 16957, 28200, 51667, 21346, 51693, 28207, 16950, 30668, 51694, 21341, 49662, 20860, 29125, 21348, 51669, 16959, 30661, 40172, 8784, 49665, 41268, 14856, 33445, 14869, 17086, 14851, 52812, 20431, 17081, 38298, 17088, 14867, 38291, 41259, 14858, 41266, 36106, 43393, 42073, 42877, 18653, 46885, 19123, 43369, 8746, 49839, 30234, 35574, 21180, 5630, 44517, 44725, 7731, 18492, 19124, 3998, 44722, 21187, 35573, 24633, 12967, 8574, 11940, 33648, 18495, 41866, 44528, 41859, 22537, 22153, 43958, 41861, 5608, 47198, 11947, 19927, 11978, 35587, 20869, 46081, 17871, 32138, 25349, 28032, 50587, 28831, 18698, 28035, 47508, 51835, 25385, 28003, 18696, 50589, 25347, 50542, 45632, 51038, 45635, 42410, 48123, 18839, 38402, 18806, 17072, 46072, 27841, 38405, 24866, 48124, 46075, 41250, 17075, 18801, 8121, 48112, 15941, 24850, 18808, 16992, 12732, 29319, 19920, 19316, 19918, 46623, 22968, 19320, 58146, 29317, 34463, 37682, 37676, 21189, 39512, 9490, 30202, 37671, 37685, 19318, 29114, 14603, 49230, 46876, 29113, 14604, 12393, 24295, 41850, 24292, 36333, 12394, 46878, 36393, 24656, 40121, 21572, 32165, 43562, 58318, 9036, 10268, 59435, 23247, 10633, 45603, 16154, 7399, 16153, 50746, 22154, 45604, 10634, 44941, 23249, 47191, 5291, 7390, 9038, 7397, 43993, 43967, 36934, 44187, 26197, 44173, 25978, 36933, 44379, 18466, 26190, 58973, 44180, 26199, 18450, 25982, 58945, 44142, 43969, 23612, 39386, 26994, 7193, 40371, 16508, 26993, 51499, 7709, 11349, 39381, 11520, 31111, 11340, 30453, 39388, 7707, 51497, 11347, 16506, 13246, 18005, 54924, 15341, 13284, 32903, 27426, 32590, 34693, 28460, 27625, 31116, 27027, 41007, 27215, 29176, 58571, 4787, 41000, 39328, 5003, 10257, 32563, 26163, 57138, 13248, 56822, 27614, 26164, 32564, 23072, 16368, 10259, 27622, 26152, 29780, 23088, 26155, 10261, 57136, 15111, 59051, 2886, 2618, 47530, 53130, 13042, 34452, 2627, 29583, 45409, 13045, 53137, 47537, 54120, 2629, 27074, 2616, 30695, 43367, 45400, 39716, 4988, 31127, 10406, 6873, 46271, 59897, 36750, 46285, 6874, 31129, 43509, 25971, 33225, 50723, 48525, 57995, 38838, 49631, 18897, 51832, 30462, 51031, 30496, 51009, 57335, 59069, 51204, 30465, 30498, 59094, 51000, 59067, 59093, 51007, 45097, 56276, 56420, 57350, 56282]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15564\\74402011.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n"]}],"source":["#In our case, we don't need every type of clothes\n","\n","top_25 = styles_df['articleType'].value_counts().sort_values(ascending=False).head(25)\n","top_25_list = top_25.index\n","print(top_25_list)\n","\n","\n","styles_df_processed = styles_df.loc[styles_df['articleType'].isin(top_25_list), :]\n","# \n","top5_each_Type = pd.DataFrame(columns=styles_df.columns)\n","\n","#we take only n elements of each type to be compared -> to reduce computation time when we recommend\n","for X in top_25_list:\n","    top5_each_Type = top5_each_Type.append(styles_df.loc[styles_df['articleType'] == X, :].head(20))\n","\n","print(top5_each_Type['id'].tolist())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gt_gsnjYgkp1"},"outputs":[],"source":["from collections import Counter\n","\n","def find_duplicate(lst):\n","    # Create a Counter object with the list\n","    element_count = Counter(lst)\n","\n","    # Iterate over the Counter and print the elements with a count greater than 1\n","    for elem, count in element_count.items():\n","        if count > 1:\n","            print(f\"Element {elem} is not unique, it appears {count} times.\")\n","\n","find_duplicate(top5_each_Type['id'].tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_6QnP7ggkp2","outputId":"5302b027-5f7c-4002-a3d6-0ad54eba5fdd"},"outputs":[{"data":{"text/plain":["'\\nj=0\\nprint(path)\\nfor i in (top5_each_Type[\\'id\\'].tolist()):\\n    plt.subplot(6, 10, j+1)\\n    try:\\n        cloth_img =  mpimg.imread(path + \\'images/\\'+ str(i) +\".jpg\")\\n    except FileNotFoundError:\\n        print(\"Could not find the specified file : \",path + \\'images/\\'+ str(i))\\n        continue\\n    except Exception as e:\\n        print(\"An error occurred:\", e)\\n    plt.imshow(cloth_img)\\n    plt.axis(\"off\")\\n    j+=1\\nplt.title(\"Recommended images\",loc=\\'left\\')\\nplt.subplots_adjust(wspace=-0.5, hspace=1)\\nplt.show()'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["\n","\"\"\"\n","j=0\n","print(path)\n","for i in (top5_each_Type['id'].tolist()):\n","    plt.subplot(6, 10, j+1)\n","    try:\n","        cloth_img =  mpimg.imread(path + 'images/'+ str(i) +\".jpg\")\n","    except FileNotFoundError:\n","        print(\"Could not find the specified file : \",path + 'images/'+ str(i))\n","        continue\n","    except Exception as e:\n","        print(\"An error occurred:\", e)\n","    plt.imshow(cloth_img)\n","    plt.axis(\"off\")\n","    j+=1\n","plt.title(\"Recommended images\",loc='left')\n","plt.subplots_adjust(wspace=-0.5, hspace=1)\n","plt.show()\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gC6nXKYLgkp3","outputId":"a1e59225-ea11-4fdf-ba3c-82945488827a"},"outputs":[{"name":"stdout","output_type":"stream","text":["         id gender masterCategory subCategory articleType baseColour  season  \\\n","4     53759    Men        Apparel     Topwear     Tshirts       Grey  Summer   \n","5      1855    Men        Apparel     Topwear     Tshirts       Grey  Summer   \n","27     7990    Men        Apparel     Topwear     Tshirts  Navy Blue    Fall   \n","31     4729   Boys        Apparel     Topwear     Tshirts      Green  Summer   \n","39     3954  Women        Apparel     Topwear     Tshirts       Pink  Summer   \n","...     ...    ...            ...         ...         ...        ...     ...   \n","1334  45097  Women        Apparel   Innerwear         Bra       Pink  Winter   \n","1422  56276  Women        Apparel   Innerwear         Bra       Skin  Summer   \n","1457  56420  Women        Apparel   Innerwear         Bra      White  Winter   \n","1575  57350  Women        Apparel   Innerwear         Bra      Black  Winter   \n","1579  56282  Women        Apparel   Innerwear         Bra      Black  Summer   \n","\n","        year   usage                                 productDisplayName  \\\n","4     2012.0  Casual                              Puma Men Grey T-shirt   \n","5     2011.0  Casual               Inkfruit Mens Chain Reaction T-shirt   \n","27    2011.0  Sports            Fila Men's Round Neck Navy Blue T-shirt   \n","31    2011.0  Casual  Disney Kids Boy's Crew Sea Life Sialing Green ...   \n","39    2011.0  Casual                    Jealous 21 Women's Pink T-shirt   \n","...      ...     ...                                                ...   \n","1334  2015.0  Casual                               Bwitch Pink Ruby Bra   \n","1422  2017.0  Casual                               Biara Women Skin Bra   \n","1457  2015.0  Casual                              Biara Women White Bra   \n","1575  2015.0  Casual                    Amante Black T-Shirt Bra BGSB01   \n","1579  2017.0  Casual                   Biara Black Everyday Support Bra   \n","\n","          image  \n","4     53759.jpg  \n","5      1855.jpg  \n","27     7990.jpg  \n","31     4729.jpg  \n","39     3954.jpg  \n","...         ...  \n","1334  45097.jpg  \n","1422  56276.jpg  \n","1457  56420.jpg  \n","1575  57350.jpg  \n","1579  56282.jpg  \n","\n","[500 rows x 11 columns]\n"]}],"source":["print(top5_each_Type)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2O8Rk6HDgkp4"},"outputs":[],"source":["img_width, img_height, chnls = 100, 100, 3\n","\n","#VGG16 is a already trained model that we fine tune here\n","from tensorflow.keras.applications import VGG16\n","\n","vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, chnls))\n","vgg16.trainable=False\n","vgg16_model = keras.Sequential([vgg16, GlobalMaxPooling2D()])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WlhYiLjgkp8"},"outputs":[],"source":["def img_path(img):\n","    \"\"\" Take image name(id) and return the complete path of it \"\"\"\n","    return path + 'images/' + img\n","\n","def predict(model, img_name):\n","    \"\"\" Load and preprocess image then make prediction \"\"\"\n","    # Reshape\n","    img = keras.utils.load_img(img_path(img_name), target_size=(img_width, img_height))\n","    # img to Array\n","    img = keras.utils.img_to_array(img)\n","    # Expand Dim (1, w, h)\n","    img = np.expand_dims(img, axis=0)\n","    # Pre process Input\n","    img = preprocess_input(img)\n","    return model.predict(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpuP3gobgkp9","outputId":"b885199d-fbfc-40aa-e66c-42c93a2a4a3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 292ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 58ms/step\n"]}],"source":["\n","\n","def get_embeddings(df, model):\n","    \"\"\" Return a dataframe contains images features \"\"\"\n","    df_copy = df\n","    df_embeddings = df_copy['image'].apply(lambda x: predict(vgg16_model, x).reshape(-1))\n","    df_embeddings = df_embeddings.apply(pd.Series)\n","    return df_embeddings\n","\n","df_embeddings = get_embeddings(top5_each_Type, vgg16_model)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlTtcKNPgkp_"},"outputs":[],"source":["from PIL import Image\n","\n","image_name = \"IMG_0546.jpg\"\n","new_image_name = \"resized_\"+image_name\n","# Open the image\n","im=Image.open(new_image_name) \n","# Resize the image\n","im_resized = im.resize((150, 150))\n","\n","# Save the resized image\n","im_resized.save(\"archive/images/\"+new_image_name)\n","im_resized.save(new_image_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"md28iOmdgkqA","outputId":"b455693e-ad5a-4cfa-e479-c16e55644b91"},"outputs":[{"ename":"NameError","evalue":"name 'new_image_name' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample_image \u001b[39m=\u001b[39m predict(vgg16_model, new_image_name)\n\u001b[0;32m      2\u001b[0m df_sample_image \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(sample_image) \n\u001b[0;32m      3\u001b[0m sample_similarity \u001b[39m=\u001b[39m linear_kernel(df_sample_image, df_embeddings)\n","\u001b[1;31mNameError\u001b[0m: name 'new_image_name' is not defined"]}],"source":["\n","\n","\n","sample_image = predict(vgg16_model, new_image_name)\n","df_sample_image = pd.DataFrame(sample_image) \n","sample_similarity = linear_kernel(df_sample_image, df_embeddings)\n","def get_similarity(model):\n","    \"\"\" Get similarity of custom image \"\"\"\n","    sample_image = predict(vgg16_model, new_image_name)\n","    df_sample_image = pd.DataFrame(sample_image)\n","    sample_similarity = linear_kernel(df_sample_image, df_embeddings)\n","    return sample_similarity\n","\n","\n","\n","def normalize_sim(similarity):\n","    \"\"\" Normalize similarity results \"\"\"\n","    x_min = similarity.min(axis=1)\n","    x_max = similarity.max(axis=1)\n","    norm = (similarity-x_min)/(x_max-x_min)[:, np.newaxis]\n","    return norm\n","\n","sample_similarity_norm = normalize_sim(sample_similarity)\n","sample_similarity_norm.shape\n","\n","def get_recommendations(df, similarity):\n","    \"\"\" Return the top 5 most similar products \"\"\"\n","    # Get the pairwsie similarity scores of all clothes with that one (index, value)\n","    sim_scores = list(enumerate(similarity[0]))\n","    \n","    # Sort the clothes based on the similarity scores\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","    \n","    # Get the scores of the 5 most similar clothes\n","    sim_scores = sim_scores[0:5]\n","    print(sim_scores)\n","    # Get the clothes indices\n","    cloth_indices = [i[0] for i in sim_scores]\n","\n","    # Return the top 5 most similar products\n","    return df['image'].iloc[cloth_indices]\n","\n","recommendation = get_recommendations(styles_df, sample_similarity_norm)\n","recommendation_list = recommendation.to_list()\n","#recommended images\n","plt.figure(figsize=(20,20))\n","j=0\n","for i in recommendation_list:\n","    plt.subplot(6, 10, j+1)\n","    print(path)\n","    cloth_img =  mpimg.imread(path + 'images/'+ i)\n","    plt.imshow(cloth_img)\n","    plt.axis(\"off\")\n","    j+=1\n","plt.title(\"Recommended images\",loc='left')\n","plt.subplots_adjust(wspace=-0.5, hspace=1)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f259b6f4857dfeaf1b5833969d3b3797da8d7bbb7fed423db1756cfd48b87eb7"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}