{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TQpeEvgWBeUG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os \n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from keras import Model\n","from keras.applications.densenet import DenseNet121\n","from keras.applications import vgg16\n","from keras.preprocessing import image\n","from keras.applications.densenet import preprocess_input, decode_predictions\n","from keras.layers import GlobalMaxPooling2D\n","from keras.utils.vis_utils import plot_model\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import pathlib\n","from sklearn.metrics.pairwise import linear_kernel\n","import tensorflow_hub as hub\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1dY3JjABeUX","outputId":"fc107592-0790-409b-dbb3-a4b442b971bf"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_26868\\1805511326.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  styles_df = pd.read_csv(path + \"styles.csv\", nrows=20000, error_bad_lines=False) # Read n product and drop bad lines\n","Skipping line 6044: expected 10 fields, saw 11\n","Skipping line 6569: expected 10 fields, saw 11\n","Skipping line 7399: expected 10 fields, saw 11\n","Skipping line 7939: expected 10 fields, saw 11\n","Skipping line 9026: expected 10 fields, saw 11\n","Skipping line 10264: expected 10 fields, saw 11\n","Skipping line 10427: expected 10 fields, saw 11\n","Skipping line 10905: expected 10 fields, saw 11\n","Skipping line 11373: expected 10 fields, saw 11\n","Skipping line 11945: expected 10 fields, saw 11\n","Skipping line 14112: expected 10 fields, saw 11\n","Skipping line 14532: expected 10 fields, saw 11\n","Skipping line 15076: expected 10 fields, saw 12\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>gender</th>\n","      <th>masterCategory</th>\n","      <th>subCategory</th>\n","      <th>articleType</th>\n","      <th>baseColour</th>\n","      <th>season</th>\n","      <th>year</th>\n","      <th>usage</th>\n","      <th>productDisplayName</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15970</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Topwear</td>\n","      <td>Shirts</td>\n","      <td>Navy Blue</td>\n","      <td>Fall</td>\n","      <td>2011</td>\n","      <td>Casual</td>\n","      <td>Turtle Check Men Navy Blue Shirt</td>\n","      <td>15970.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39386</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Bottomwear</td>\n","      <td>Jeans</td>\n","      <td>Blue</td>\n","      <td>Summer</td>\n","      <td>2012</td>\n","      <td>Casual</td>\n","      <td>Peter England Men Party Blue Jeans</td>\n","      <td>39386.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>59263</td>\n","      <td>Women</td>\n","      <td>Accessories</td>\n","      <td>Watches</td>\n","      <td>Watches</td>\n","      <td>Silver</td>\n","      <td>Winter</td>\n","      <td>2016</td>\n","      <td>Casual</td>\n","      <td>Titan Women Silver Watch</td>\n","      <td>59263.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21379</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Bottomwear</td>\n","      <td>Track Pants</td>\n","      <td>Black</td>\n","      <td>Fall</td>\n","      <td>2011</td>\n","      <td>Casual</td>\n","      <td>Manchester United Men Solid Black Track Pants</td>\n","      <td>21379.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>53759</td>\n","      <td>Men</td>\n","      <td>Apparel</td>\n","      <td>Topwear</td>\n","      <td>Tshirts</td>\n","      <td>Grey</td>\n","      <td>Summer</td>\n","      <td>2012</td>\n","      <td>Casual</td>\n","      <td>Puma Men Grey T-shirt</td>\n","      <td>53759.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id gender masterCategory subCategory  articleType baseColour  season  \\\n","0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n","1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n","2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n","3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n","4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n","\n","   year   usage                             productDisplayName      image  \n","0  2011  Casual               Turtle Check Men Navy Blue Shirt  15970.jpg  \n","1  2012  Casual             Peter England Men Party Blue Jeans  39386.jpg  \n","2  2016  Casual                       Titan Women Silver Watch  59263.jpg  \n","3  2011  Casual  Manchester United Men Solid Black Track Pants  21379.jpg  \n","4  2012  Casual                          Puma Men Grey T-shirt  53759.jpg  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["path = 'archive/'\n","dataset_path = pathlib.Path(path)\n","dirs_names = os.listdir(dataset_path) # list content of dataset\n","dirs_names\n","\n","styles_df = pd.read_csv(path + \"styles.csv\", nrows=20000, error_bad_lines=False) # Read n product and drop bad lines \n","styles_df['image'] = styles_df.apply(lambda x: str(x['id']) + \".jpg\", axis=1) # Make image column contains (id.jpg)\n","styles_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtBHv01fBeUc","outputId":"3e7e46cc-b575-4d23-ad64-af2e11a52c52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Tshirts', 'Shirts', 'Casual Shoes', 'Watches', 'Sports Shoes',\n","       'Kurtas', 'Tops', 'Handbags', 'Heels', 'Sunglasses', 'Flip Flops',\n","       'Wallets', 'Sandals', 'Briefs', 'Belts', 'Backpacks', 'Socks',\n","       'Perfume and Body Mist', 'Formal Shoes', 'Jeans', 'Trousers', 'Shorts',\n","       'Flats', 'Bra', 'Sarees'],\n","      dtype='object')\n"]}],"source":["top_25 = styles_df['articleType'].value_counts().sort_values(ascending=False).head(25)\n","top_25_list = top_25.index\n","print(top_25_list)\n","\n","\n","# get only data with the more used \n","styles_df_processed = styles_df.loc[styles_df['articleType'].isin(top_25_list), :]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLgT62reBeUj"},"outputs":[],"source":["#function for Preprocessing the data \n","\n","# Inputs must respect these conditions : \n","\n","   # be four dimensional Tensors of the shape (batch_size, height, width, num_channels). Note that the model expects images with channels_last property. num_channels must be 3.\n","   # be resized to 224x224 resolution.\n","   # have pixel values in the range [-1, 1].\n","\n","def img_path(img):\n","    \"\"\" Take image name(id) and return the complete path of it \"\"\"\n","    return path + 'images/' + img\n","\n","def preprocess_image(image_path):\n","    # Load the image from file\n","    image = tf.io.read_file(image_path)\n","    \n","    # Decode the image and convert it to a tensor\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    \n","    # Convert the data to a four-dimensional tensor\n","    image = tf.expand_dims(image, axis=0)\n","    \n","    # Resize the data to a resolution of 224x224\n","    image = tf.image.resize(image, (224, 224))\n","    \n","    # Normalize the pixel values to the range [-1, 1]\n","    image = (image / 127.5) - 1\n","    \n","    # Add a channels dimension to the data\n","    image = tf.transpose(image, (0, 3, 1, 2))\n","    \n","    return image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgNL29hABeUo","outputId":"efa51b18-cd52-4be1-db17-54cb2c886d9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["not enough row and columns\n","not enough row and columns\n"]},{"ename":"MemoryError","evalue":"Unable to allocate 8.97 GiB for an array with shape (15989, 1, 3, 224, 224) and data type float32","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn [14], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(images)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m images,error_num\n\u001b[1;32m---> 45\u001b[0m images,error_num \u001b[39m=\u001b[39m load_images_from_files(styles_df_processed[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist())\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_labels\u001b[39m(dataset,error_list):\n\u001b[0;32m     48\u001b[0m     res \u001b[39m=\u001b[39m []\n","Cell \u001b[1;32mIn [14], line 41\u001b[0m, in \u001b[0;36mload_images_from_files\u001b[1;34m(image_files)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAn error occurred:\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m     40\u001b[0m \u001b[39m# Convert the list of images to a numpy array\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(images)\n\u001b[0;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m images,error_num\n","\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.97 GiB for an array with shape (15989, 1, 3, 224, 224) and data type float32"]}],"source":["def load_labels_from_files(label_files):\n","    path = 'archive/'\n","    dataset_path = pathlib.Path(path)\n","    dirs_names = os.listdir(dataset_path) # list content of dataset\n","    # Create an empty list to store the labels\n","    labels = []\n","\n","    # Iterate over the label files\n","    styles_df = pd.read_csv(path + \"styles.csv\", nrows=10000, error_bad_lines=False) # Read n product and drop bad lines \n","    styles_df['image'] = styles_df.apply(lambda x: str(x['id']) + \".jpg\", axis=1) # Make image column contains (id.jpg)\n","\n","    return labels\n","\n","def load_images_from_files(image_files):\n","  \n","    # Create an empty list to store the images\n","    images = []\n","    error_num =[]\n","    # Iterate over the image files\n","    for file in image_files:\n","        # Load the image using PIL\n","        try:\n","            \n","            image = preprocess_image(img_path(file))\n","            images.append(image)\n","        except FileNotFoundError:\n","            print(\"Could not find the specified file : \",path + 'images/')\n","            error_num.append(file)\n","            continue\n","        except ValueError:\n","            print(\"not enough row and columns\")\n","            error_num.append(file)\n","            continue\n","        except Exception as e:\n","            error_num.append(file)\n","            print(\"An error occurred:\", e)\n","        \n","        \n","\n","    # Convert the list of images to a numpy array\n","    images = np.array(images)\n","\n","    return images,error_num\n","\n","images,error_num = load_images_from_files(styles_df_processed['image'].tolist())\n","\n","def get_labels(dataset,error_list):\n","    res = []\n","    for rows in dataset:\n","        if rows['image'] not in error_list:\n","            res.append(rows['articleType'])\n","        else: \n","            pass\n","    return res\n"," \n","labels = get_labels(styles_df_processed,error_num)\n","print(len(images))\n","print(len(labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVOPGROSBeVO","outputId":"91135ec1-7b26-4e22-f249-00a40bfe6689"},"outputs":[{"name":"stdout","output_type":"stream","text":["15989\n","15991\n"]}],"source":["print(len(images))\n","print(len(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9nckZgVBeVf","outputId":"c0f03796-06ce-4981-ea2f-d245eff99c79"},"outputs":[{"name":"stdout","output_type":"stream","text":["<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020817CE9F00>>\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","IMAGE_SHAPE = (224, 224)\n","# Load the pre-trained model from TensorFlow Hub\n","classifier_model = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n","model = tf.keras.Sequential([\n","    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n","])\n","\n","\n","\n","print(model.summary)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R45aubO-BeVn","outputId":"76e1fa36-2112-46d8-b770-804a3845dc70"},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [15989, 15991]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn [10], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(images, labels, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Train the model on your dataset\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n","File \u001b[1;32mc:\\Users\\samis\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2450\u001b[0m )\n","File \u001b[1;32mc:\\Users\\samis\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\samis\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15989, 15991]"]}],"source":["\n","\n","\n","# Replace the top layers of the model\n","num_classes = 10  # Number of classes in your dataset\n","x = model.output\n","x = tf.keras.layers.Flatten()(x)\n","x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n","model = tf.keras.Model(inputs=model.input, outputs=predictions)\n","\n","# Freeze the weights of the pre-trained layers\n","for layer in model.layers[:-3]:\n","    layer.trainable = False\n","\n","# Compile the model\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n","\n","# Train the model on your dataset\n","model.fit(x_train, y_train, epochs=10, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0fVq_JdBeVr"},"outputs":[],"source":["test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(test_loss,\" \",test_acc)"]}],"metadata":{"kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f259b6f4857dfeaf1b5833969d3b3797da8d7bbb7fed423db1756cfd48b87eb7"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}