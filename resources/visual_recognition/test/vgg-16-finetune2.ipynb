{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import Model\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.densenet import preprocess_input, decode_predictions\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pathlib\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samis\\AppData\\Local\\Temp\\ipykernel_15340\\1805511326.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  styles_df = pd.read_csv(path + \"styles.csv\", nrows=20000, error_bad_lines=False) # Read n product and drop bad lines\n",
      "Skipping line 6044: expected 10 fields, saw 11\n",
      "Skipping line 6569: expected 10 fields, saw 11\n",
      "Skipping line 7399: expected 10 fields, saw 11\n",
      "Skipping line 7939: expected 10 fields, saw 11\n",
      "Skipping line 9026: expected 10 fields, saw 11\n",
      "Skipping line 10264: expected 10 fields, saw 11\n",
      "Skipping line 10427: expected 10 fields, saw 11\n",
      "Skipping line 10905: expected 10 fields, saw 11\n",
      "Skipping line 11373: expected 10 fields, saw 11\n",
      "Skipping line 11945: expected 10 fields, saw 11\n",
      "Skipping line 14112: expected 10 fields, saw 11\n",
      "Skipping line 14532: expected 10 fields, saw 11\n",
      "Skipping line 15076: expected 10 fields, saw 12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "      <td>15970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "      <td>39386.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "      <td>59263.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "      <td>21379.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "      <td>53759.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "   year   usage                             productDisplayName      image  \n",
       "0  2011  Casual               Turtle Check Men Navy Blue Shirt  15970.jpg  \n",
       "1  2012  Casual             Peter England Men Party Blue Jeans  39386.jpg  \n",
       "2  2016  Casual                       Titan Women Silver Watch  59263.jpg  \n",
       "3  2011  Casual  Manchester United Men Solid Black Track Pants  21379.jpg  \n",
       "4  2012  Casual                          Puma Men Grey T-shirt  53759.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'archive/'\n",
    "dataset_path = pathlib.Path(path)\n",
    "dirs_names = os.listdir(dataset_path) # list content of dataset\n",
    "dirs_names\n",
    "\n",
    "styles_df = pd.read_csv(path + \"styles.csv\", nrows=20000, error_bad_lines=False) # Read n product and drop bad lines \n",
    "styles_df['image'] = styles_df.apply(lambda x: str(x['id']) + \".jpg\", axis=1) # Make image column contains (id.jpg)\n",
    "styles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tshirts', 'Shirts', 'Casual Shoes', 'Watches', 'Sports Shoes',\n",
      "       'Kurtas', 'Tops', 'Handbags', 'Heels', 'Sunglasses', 'Flip Flops',\n",
      "       'Wallets', 'Sandals', 'Briefs', 'Belts', 'Backpacks', 'Socks',\n",
      "       'Perfume and Body Mist', 'Formal Shoes', 'Jeans', 'Trousers', 'Shorts',\n",
      "       'Flats', 'Bra', 'Sarees'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "top_25 = styles_df['articleType'].value_counts().sort_values(ascending=False).head(25)\n",
    "top_25_list = top_25.index\n",
    "print(top_25_list)\n",
    "\n",
    "\n",
    "# get only data with the more used \n",
    "styles_df_processed = styles_df.loc[styles_df['articleType'].isin(top_25_list), :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for Preprocessing the data \n",
    "\n",
    "# Inputs must respect these conditions : \n",
    "\n",
    "   # be four dimensional Tensors of the shape (batch_size, height, width, num_channels). Note that the model expects images with channels_last property. num_channels must be 3.\n",
    "   # be resized to 224x224 resolution.\n",
    "   # have pixel values in the range [-1, 1].\n",
    "\n",
    "def img_path(img):\n",
    "    \"\"\" Take image name(id) and return the complete path of it \"\"\"\n",
    "    return path + 'images/' + img\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image from file\n",
    "    image = tf.io.read_file(image_path)\n",
    "    \n",
    "    # Decode the image and convert it to a tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Convert the data to a four-dimensional tensor\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Resize the data to a resolution of 224x224\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    \n",
    "    # Normalize the pixel values to the range [-1, 1]\n",
    "    image = (image / 127.5) - 1\n",
    "    \n",
    "    # Add a channels dimension to the data\n",
    "    image = tf.transpose(image, (0, 3, 1, 2))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough row and columns\n",
      "not enough row and columns\n"
     ]
    }
   ],
   "source": [
    "def load_labels_from_files(label_files):\n",
    "    path = 'archive/'\n",
    "    dataset_path = pathlib.Path(path)\n",
    "    dirs_names = os.listdir(dataset_path) # list content of dataset\n",
    "    # Create an empty list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over the label files\n",
    "    styles_df = pd.read_csv(path + \"styles.csv\", nrows=40000, error_bad_lines=False) # Read n product and drop bad lines \n",
    "    styles_df['image'] = styles_df.apply(lambda x: str(x['id']) + \".jpg\", axis=1) # Make image column contains (id.jpg)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def load_images_from_files(image_files):\n",
    "  \n",
    "    # Create an empty list to store the images\n",
    "    images = []\n",
    "\n",
    "    # Iterate over the image files\n",
    "    for file in image_files:\n",
    "        # Load the image using PIL\n",
    "        try:\n",
    "            \n",
    "            image = preprocess_image(img_path(file))\n",
    "            images.append(image)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Could not find the specified file : \",path + 'images/')\n",
    "            continue\n",
    "        except ValueError:\n",
    "            print(\"not enough row and columns\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Convert the list of images to a numpy array\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images\n",
    "\n",
    "images = load_images_from_files(styles_df_processed['image'].tolist())\n",
    "labels = styles_df_processed['articleType'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020B9D480C40>>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Load the pretrained VGG16 model\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze the parameters of the convolutional layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the fully connected layers with a new fully connected layer\n",
    "# that has the same number of output units as the number of classes in the new dataset\n",
    "num_classes = 10\n",
    "model.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(...)\n",
    "val_dataset = torchvision.datasets.ImageFolder(...)\n",
    "\n",
    "# Define the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Fine-tune the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        print(\"Epoch {}: Validation Accuracy = {}\".format(epoch+1, val_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_loss,\" \",test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f259b6f4857dfeaf1b5833969d3b3797da8d7bbb7fed423db1756cfd48b87eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
